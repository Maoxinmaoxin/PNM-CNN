{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      filename  porosity  permeability  formation_factor      file_path\n",
      "0  image_0.png    0.7821      8.295445          2.205310  1\\image_0.png\n",
      "1  image_1.png    0.6901      2.168622          3.531883  1\\image_1.png\n",
      "2  image_2.png    0.1971      0.002521        339.209059  1\\image_2.png\n",
      "3  image_3.png    0.3980      0.000852        476.741173  1\\image_3.png\n",
      "4  image_4.png    0.5590      3.153554          4.694168  1\\image_4.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 读取数据\n",
    "data_path = 'results.txt'\n",
    "data = pd.read_csv(data_path, header=None, names=['filename', 'porosity', 'permeability', 'formation_factor'])\n",
    "\n",
    "# 定义生成图像路径的函数\n",
    "def generate_image_path(filename):\n",
    "    basename = os.path.splitext(filename)[0]  # 去掉扩展名\n",
    "    image_index = int(basename.split('_')[1])  # 提取数字部分\n",
    "    folder_index = image_index // 100 + 1  # 计算文件夹索引\n",
    "    return os.path.join(str(folder_index), filename)\n",
    "\n",
    "# 假设图像文件在当前目录下的子文件夹中\n",
    "#image_base_path = 'path/to/images'\n",
    "\n",
    "# 添加图像路径到数据框\n",
    "#data['file_path'] = data['filename'].apply(lambda x: os.path.join(image_base_path, generate_image_path(x)))\n",
    "data['file_path'] = data['filename'].apply(lambda x: os.path.join(generate_image_path(x)))\n",
    "data['porosity'] = pd.to_numeric(data['porosity'], errors='coerce')\n",
    "data['permeability'] = pd.to_numeric(data['permeability'], errors='coerce')\n",
    "data['formation_factor'] = pd.to_numeric(data['formation_factor'], errors='coerce')\n",
    "# 检查数据框\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      filename  porosity  permeability  formation_factor      file_path\n",
      "0  image_0.png    0.7821      8.295445          2.205310  1\\image_0.png\n",
      "1  image_1.png    0.6901      2.168622          3.531883  1\\image_1.png\n",
      "2  image_2.png    0.1971      0.002521        339.209059  1\\image_2.png\n",
      "3  image_3.png    0.3980      0.000852        476.741173  1\\image_3.png\n",
      "4  image_4.png    0.5590      3.153554          4.694168  1\\image_4.png\n",
      "原始数据行数: 1000, 过滤后数据行数: 958\n"
     ]
    }
   ],
   "source": [
    "# 去除渗透率或形成因子小于0的行\n",
    "filtered_data = data[(data['permeability'] >= 0) & (data['formation_factor'] >= 0)]\n",
    "\n",
    "# 检查过滤后的数据框\n",
    "print(filtered_data.head())\n",
    "print(f\"原始数据行数: {len(data)}, 过滤后数据行数: {len(filtered_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         porosity  permeability  formation_factor\n",
      "count  958.000000  9.580000e+02      9.580000e+02\n",
      "mean     0.489896  2.157759e+00      6.554743e+13\n",
      "std      0.170661  2.861522e+00      9.556576e+14\n",
      "min      0.175000  4.159036e-15      1.617284e+00\n",
      "25%      0.346350  3.258744e-02      3.998784e+00\n",
      "50%      0.490000  9.301814e-01      1.009481e+01\n",
      "75%      0.632050  3.389625e+00      9.149953e+01\n",
      "max      0.799100  2.120012e+01      2.492943e+16\n"
     ]
    }
   ],
   "source": [
    "print(filtered_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      filename  porosity  permeability  formation_factor      file_path\n",
      "0  image_0.png  1.713082      2.146023         -0.068625  1\\image_0.png\n",
      "1  image_1.png  1.173722      0.003798         -0.068625  1\\image_1.png\n",
      "2  image_2.png -1.716547     -0.753572         -0.068625  1\\image_2.png\n",
      "3  image_3.png -0.538748     -0.754156         -0.068625  1\\image_3.png\n",
      "4  image_4.png  0.405133      0.348177         -0.068625  1\\image_4.png\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 创建一个StandardScaler对象\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 对'porosity', 'permeability', 'formation_factor'进行标准化处理\n",
    "standardized_data = filtered_data.copy()  # 复制数据框以免修改原始数据\n",
    "standardized_data[['porosity', 'permeability', 'formation_factor']] = scaler.fit_transform(filtered_data[['porosity', 'permeability', 'formation_factor']])\n",
    "\n",
    "# 打印标准化后的数据框\n",
    "print(standardized_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.4181\n",
      "Validation Loss: 1.1202\n",
      "Epoch [2/20], Loss: 1.5804\n",
      "Validation Loss: 0.7739\n",
      "Epoch [3/20], Loss: 1.5100\n",
      "Validation Loss: 0.8218\n",
      "Epoch [4/20], Loss: 1.5169\n",
      "Validation Loss: 0.8000\n",
      "Epoch [5/20], Loss: 1.4840\n",
      "Validation Loss: 0.7590\n",
      "Epoch [6/20], Loss: 1.4420\n",
      "Validation Loss: 0.7614\n",
      "Epoch [7/20], Loss: 1.4438\n",
      "Validation Loss: 0.7532\n",
      "Epoch [8/20], Loss: 1.3972\n",
      "Validation Loss: 0.7760\n",
      "Epoch [9/20], Loss: 1.4289\n",
      "Validation Loss: 0.7748\n",
      "Epoch [10/20], Loss: 1.4055\n",
      "Validation Loss: 0.7769\n",
      "Epoch [11/20], Loss: 1.4035\n",
      "Validation Loss: 0.8009\n",
      "Epoch [12/20], Loss: 1.3519\n",
      "Validation Loss: 0.7562\n",
      "Epoch [13/20], Loss: 1.3678\n",
      "Validation Loss: 0.7638\n",
      "Epoch [14/20], Loss: 1.3312\n",
      "Validation Loss: 0.7740\n",
      "Epoch [15/20], Loss: 1.2960\n",
      "Validation Loss: 0.8247\n",
      "Epoch [16/20], Loss: 1.3206\n",
      "Validation Loss: 0.7585\n",
      "Epoch [17/20], Loss: 1.3557\n",
      "Validation Loss: 0.7741\n",
      "Epoch [18/20], Loss: 1.2229\n",
      "Validation Loss: 0.7689\n",
      "Epoch [19/20], Loss: 1.2351\n",
      "Validation Loss: 0.8432\n",
      "Epoch [20/20], Loss: 1.0411\n",
      "Validation Loss: 0.7515\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "# 设置使用的设备：GPU或者CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 定义数据集类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.dataframe.iloc[idx]['file_path']\n",
    "        image = Image.open(image_path).convert('L')  # 以灰度模式打开图像\n",
    "        label1 = torch.tensor(self.dataframe.iloc[idx]['porosity'], dtype=torch.float32)\n",
    "        label2 = torch.tensor(self.dataframe.iloc[idx]['permeability'], dtype=torch.float32)\n",
    "        label3 = torch.tensor(self.dataframe.iloc[idx]['formation_factor'], dtype=torch.float32)\n",
    "                \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, (label1, label2, label3)\n",
    "\n",
    "# 数据增强和转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整图像大小\n",
    "    transforms.ToTensor(),           # 转换为张量\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # 标准化，因为是灰度图，只有一个通道\n",
    "])\n",
    "\n",
    "# 创建数据集实例\n",
    "dataset = CustomDataset(filtered_data, transform=transform)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# 定义多任务学习的CNN模型\n",
    "class MultiTaskCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),  # 输入通道改为1\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.Linear(128 * 7 * 7, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 1)  # 任务1：porosity，输出为1维\n",
    "        )\n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(128 * 7 * 7, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 1)  # 任务2：permeability，输出为1维\n",
    "        )\n",
    "        self.classifier3 = nn.Sequential(\n",
    "            nn.Linear(128 * 7 * 7, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 1)  # 任务3：formation_factor，输出为1维\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        output1 = self.classifier1(x)\n",
    "        output2 = self.classifier2(x)\n",
    "        output3 = self.classifier3(x)\n",
    "        return output1, output2, output3\n",
    "\n",
    "# 实例化模型和损失函数\n",
    "model = MultiTaskCNN().to(device)\n",
    "criterion = nn.MSELoss()  # 使用均方误差作为损失函数\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            target1, target2, target3 = targets\n",
    "            target1 = target1.to(device)\n",
    "            target2 = target2.to(device)\n",
    "            target3 = target3.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs1, outputs2, outputs3 = model(inputs)\n",
    "            \n",
    "            loss1 = criterion(outputs1, target1.unsqueeze(1))  # 添加维度以匹配输出形状\n",
    "            loss2 = criterion(outputs2, target2.unsqueeze(1))\n",
    "            loss3 = criterion(outputs3, target3.unsqueeze(1))\n",
    "            \n",
    "            loss = loss1 + loss2 + loss3\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # 在验证集上评估模型\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                target1, target2, target3 = targets\n",
    "                target1 = target1.to(device)\n",
    "                target2 = target2.to(device)\n",
    "                target3 = target3.to(device)\n",
    "                \n",
    "                outputs1, outputs2, outputs3 = model(inputs)\n",
    "                \n",
    "                loss1 = criterion(outputs1, target1.unsqueeze(1))\n",
    "                loss2 = criterion(outputs2, target2.unsqueeze(1))\n",
    "                loss3 = criterion(outputs3, target3.unsqueeze(1))\n",
    "                \n",
    "                val_loss += (loss1 + loss2 + loss3).item() * inputs.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# 开始训练\n",
    "train_model(model, criterion, optimizer, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE for Porosity: 0.0117\n",
      "Average MSE for Permeability: 0.3427\n",
      "Average MSE for Formation Factor: 0.3971\n"
     ]
    }
   ],
   "source": [
    "# 定义评估函数，用于计算每个任务的MSE\n",
    "def evaluate_model_on_val_set(model, val_loader, device):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    task_mse = {'Porosity': [], 'Permeability': [], 'Formation Factor': []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            target1, target2, target3 = targets\n",
    "            target1 = target1.to(device)\n",
    "            target2 = target2.to(device)\n",
    "            target3 = target3.to(device)\n",
    "\n",
    "            outputs1, outputs2, outputs3 = model(inputs)\n",
    "\n",
    "            # 计算每个任务的MSE\n",
    "            mse1 = torch.mean((outputs1 - target1.unsqueeze(1)) ** 2)\n",
    "            mse2 = torch.mean((outputs2 - target2.unsqueeze(1)) ** 2)\n",
    "            mse3 = torch.mean((outputs3 - target3.unsqueeze(1)) ** 2)\n",
    "\n",
    "            # 将MSE添加到列表中\n",
    "            task_mse['Porosity'].append(mse1.item())\n",
    "            task_mse['Permeability'].append(mse2.item())\n",
    "            task_mse['Formation Factor'].append(mse3.item())\n",
    "\n",
    "    # 计算每个任务的平均MSE\n",
    "    for task, mse_values in task_mse.items():\n",
    "        average_mse = sum(mse_values) / len(mse_values)\n",
    "        print(f\"Average MSE for {task}: {average_mse:.4f}\")\n",
    "\n",
    "# 假设你已经有了验证集数据加载器val_loader\n",
    "# device 已经定义为使用GPU或CPU\n",
    "# model 是已经训练好的模型\n",
    "\n",
    "# 使用验证集评估模型性能\n",
    "evaluate_model_on_val_set(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for Porosity:\n",
      "  MSE: 0.0117\n",
      "  RMSE: 0.1081\n",
      "  MAE: 0.0982\n",
      "  R^2: 0.9878\n",
      "Evaluation results for Permeability:\n",
      "  MSE: 0.3427\n",
      "  RMSE: 0.5854\n",
      "  MAE: 0.3259\n",
      "  R^2: 0.6939\n",
      "Evaluation results for Formation Factor:\n",
      "  MSE: 0.3971\n",
      "  RMSE: 0.6301\n",
      "  MAE: 0.0834\n",
      "  R^2: -0.0090\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "# 定义评估函数，用于计算多个评估指标\n",
    "def evaluate_model_multi_metrics(model, val_loader, device):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    true_values = {'Porosity': [], 'Permeability': [], 'Formation Factor': []}\n",
    "    predictions = {'Porosity': [], 'Permeability': [], 'Formation Factor': []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            target1, target2, target3 = targets\n",
    "            target1 = target1.to(device)\n",
    "            target2 = target2.to(device)\n",
    "            target3 = target3.to(device)\n",
    "\n",
    "            outputs1, outputs2, outputs3 = model(inputs)\n",
    "\n",
    "            # 存储真实值和预测值\n",
    "            true_values['Porosity'].append(target1.cpu().numpy())\n",
    "            true_values['Permeability'].append(target2.cpu().numpy())\n",
    "            true_values['Formation Factor'].append(target3.cpu().numpy())\n",
    "\n",
    "            predictions['Porosity'].append(outputs1.cpu().numpy())\n",
    "            predictions['Permeability'].append(outputs2.cpu().numpy())\n",
    "            predictions['Formation Factor'].append(outputs3.cpu().numpy())\n",
    "\n",
    "    # 将列表转换为数组\n",
    "    for task in true_values.keys():\n",
    "        true_values[task] = np.concatenate(true_values[task])\n",
    "        predictions[task] = np.concatenate(predictions[task])\n",
    "\n",
    "    # 计算评估指标\n",
    "    results = {}\n",
    "    for task in true_values.keys():\n",
    "        mse = mean_squared_error(true_values[task], predictions[task])\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(true_values[task], predictions[task])\n",
    "        r2 = r2_score(true_values[task], predictions[task])\n",
    "\n",
    "        results[task] = {\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R^2': r2\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# 使用验证集评估模型性能\n",
    "results = evaluate_model_multi_metrics(model, val_loader, device)\n",
    "\n",
    "# 打印结果\n",
    "for task, metrics in results.items():\n",
    "    print(f\"Evaluation results for {task}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
